{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import nltk\n",
    "from collections import Counter\n",
    "import spacy\n",
    "from tqdm import tqdm, tqdm_notebook, tnrange\n",
    "tqdm.pandas(desc=\"Progress\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../input/train.csv\")\n",
    "test_df = pd.read_csv(\"../input/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en', disable=['parser', 'tagger', 'ner'])\n",
    "# train_df.question_text = train_df.question_text.progress_apply(lambda x: x.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1306122/1306122 [01:52<00:00, 11635.04it/s]\n"
     ]
    }
   ],
   "source": [
    "words = Counter()\n",
    "for sent in tqdm(train_df.question_text.values):\n",
    "    words.update(w.text.lower() for w in nlp(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = sorted(words, key=words.get, reverse=True)\n",
    "words = ['_PAD', '_UNK'] + words\n",
    "\n",
    "word2idx = {o:i for i, o in enumerate(words)}\n",
    "idx2word = {i:o for i,o in enumerate(words)}\n",
    "\n",
    "def indexer(s):\n",
    "    return [word2idx[w.text.lower()] for w in nlp(s)]\n",
    "\n",
    "# train_df['question_idx'] = train_df.question_text.progress_apply(indexer)\n",
    "# train_df['lengths'] = train_df.question_idx.progress_apply(len)\n",
    "\n",
    "# fig = plt.figure(figsize=(8,5))\n",
    "# ax = sns.distplot(train_df.lengths.values, kde=False);\n",
    "# ax.set(xlabel='Question length', ylabel='Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00002165364db923c7e6</td>\n",
       "      <td>How did Quebec nationalists see their province...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000032939017120e6e44</td>\n",
       "      <td>Do you have an adopted dog, how would you enco...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000412ca6e4628ce2cf</td>\n",
       "      <td>Why does velocity affect time? Does velocity a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000042bf85aa498cd78e</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000455dfa3e01eae3af</td>\n",
       "      <td>Can I convert montra helicon D to a mountain b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid                                      question_text  \\\n",
       "0  00002165364db923c7e6  How did Quebec nationalists see their province...   \n",
       "1  000032939017120e6e44  Do you have an adopted dog, how would you enco...   \n",
       "2  0000412ca6e4628ce2cf  Why does velocity affect time? Does velocity a...   \n",
       "3  000042bf85aa498cd78e  How did Otto von Guericke used the Magdeburg h...   \n",
       "4  0000455dfa3e01eae3af  Can I convert montra helicon D to a mountain b...   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "# class VectorizeData(Dataset):\n",
    "#     def __init__(self, df_path):\n",
    "#         self.df = pd.read_csv(df_path, error_bad_lines=False)\n",
    "#         self.df['question_text'] = self.df.question_text.progress_apply(lambda x: x.strip())\n",
    "#         self.df['question_idx'] = self.df.question_text.progress_apply(indexer)\n",
    "    \n",
    "#     def __len__(self):\n",
    "#         return self.df.shape[0]\n",
    "    \n",
    "#     def __getitem__(self, idx):\n",
    "#         X = self.df.question_idx[idx]\n",
    "#         y = self.df.target[idx]\n",
    "#         return X, y\n",
    "    \n",
    "\n",
    "# ds = VectorizeData('../input/train.csv')\n",
    "# print(ds[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples 435374\n"
     ]
    }
   ],
   "source": [
    "d1 = DataLoader(dataset=ds, batch_size=3)\n",
    "print('Total samples', len(d1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of smallest question 12\n",
      "<class 'list'>\n",
      "[tensor([11, 12, 19]), tensor([55, 17, 28]), tensor([6650,   27, 2016]), tensor([7135,   35,  385]), tensor([ 167, 3872,   81]), tensor([ 65, 481,   2]), tensor([6106,   15,   28]), tensor([  42,   11, 2016]), tensor([  6,  40, 385]), tensor([1156,   17,  461]), tensor([   8, 3665, 5524]), tensor([ 3, 44,  2])]\n"
     ]
    }
   ],
   "source": [
    "it = iter(d1)\n",
    "xs, ys = next(it)\n",
    "print('length of smallest question', len(xs))\n",
    "print(type(xs))\n",
    "print(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|██████████| 1306122/1306122 [00:01<00:00, 915833.86it/s]\n",
      "Progress:   0%|          | 46/1306122 [00:00<47:19, 459.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|██████████| 1306122/1306122 [01:44<00:00, 12497.33it/s]\n",
      "Progress:   5%|▌         | 65861/1306122 [00:00<00:01, 658609.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating lengths\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|██████████| 1306122/1306122 [00:01<00:00, 914422.88it/s] \n",
      "Progress:   1%|          | 13854/1306122 [00:00<00:09, 138536.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|██████████| 1306122/1306122 [00:05<00:00, 243123.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0    [11, 55, 6650, 7135, 167, 65, 6106, 42, 6, 115...\n",
      "1    [12, 17, 27, 35, 3872, 481, 15, 11, 40, 17, 36...\n",
      "2    [19, 28, 2016, 385, 81, 2, 28, 2016, 385, 461,...\n",
      "3    [11, 55, 12687, 8277, 51252, 130, 3, 39440, 27...\n",
      "4    [18, 10, 1134, 42451, 96201, 1368, 7, 6, 3137,...\n",
      "Name: question_padded, dtype: object, 0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "Name: target, dtype: int64, 0    14\n",
      "1    18\n",
      "2    12\n",
      "3    10\n",
      "4    16\n",
      "Name: lengths, dtype: int64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class VectorizeData(Dataset):\n",
    "    def __init__(self, df_path, maxlen=100):\n",
    "        self.maxlen = maxlen\n",
    "        self.df = pd.read_csv(df_path, error_bad_lines = False)\n",
    "        self.df['question_text'] = self.df.question_text.progress_apply(lambda x: x.strip())\n",
    "        print('Indexing...')\n",
    "        self.df['question_idx'] = self.df.question_text.progress_apply(indexer)\n",
    "        print('Calculating lengths')\n",
    "        self.df['lengths'] = self.df.question_idx.progress_apply(lambda x: self.maxlen if len(x)>self.maxlen else len(x))\n",
    "        print('Padding')\n",
    "        self.df['question_padded'] = self.df.question_idx.progress_apply(self.pad_data)\n",
    "    \n",
    "    def pad_data(self, s):\n",
    "        padded = np.zeros((self.maxlen,), dtype=np.int64)\n",
    "        if len(s) > self.maxlen: padded[:]=s[:self.maxlen]\n",
    "        else: padded[:len(s)] = s\n",
    "        return padded\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        X = self.df.question_padded[idx]\n",
    "        lens = self.df.lengths[idx]\n",
    "        y = self.df.target[idx]\n",
    "        return X, y, lens\n",
    "    \n",
    "ds = VectorizeData('../input/train.csv')\n",
    "print(ds[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "435374\n"
     ]
    }
   ],
   "source": [
    "d1 = DataLoader(dataset=ds, batch_size=3)\n",
    "print(len(d1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor([[  11,   55, 6650, 7135,  167,   65, 6106,   42,    6, 1156,    8,    3,\n",
      "         8597,    2,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [  12,   17,   27,   35, 3872,  481,   15,   11,   40,   17, 3665,   44,\n",
      "            7, 3102,   13,   51, 1858,    2,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [  19,   28, 2016,  385,   81,    2,   28, 2016,  385,  461, 5524,    2,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0]])\n"
     ]
    }
   ],
   "source": [
    "it = iter(d1)\n",
    "xs, ys, lens = next(it)\n",
    "print(type(xs))\n",
    "print(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(words)\n",
    "embedding_dim = 4\n",
    "n_hidden = 5\n",
    "n_out = 2\n",
    "\n",
    "class SimpleGru(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, n_hidden, n_out):\n",
    "        super().__init__()\n",
    "        self.vocab_size, self.embedding_dim, self.n_hidden, self.n_out = vocab_size, embedding_dim, n_hidden, n_out\n",
    "        self.emb = nn.Embedding(self.vocab_size, self.embedding_dim)\n",
    "        self.gru = nn.GRU(self.embedding_dim, self.n_hidden)\n",
    "        self.out = nn.Linear(self.n_hidden, self.n_out)\n",
    "    \n",
    "    def forward(self, seq, lengths):\n",
    "        bs = seq.size(1)\n",
    "#         print('batch size', bs)\n",
    "        self.h = self.init_hidden(bs) #initialize hidden state of GRU\n",
    "#         print('Initial hidden state shape: ', self.h.shape)\n",
    "        embs = self.emb(seq)\n",
    "        embs = pack_padded_sequence(embs, lengths) #unpad\n",
    "        gru_out, self.h = self.gru(embs, self.h) #gru returns hidden state of all timesteps and hidden state at last timestep\n",
    "        gru_out, lengths = pad_packed_sequence(gru_out) #pad the sequence to the  max length in the batch\n",
    "#         print('GRU output(all timesteps): ', gru_out.shape)\n",
    "#         print(gru_out)\n",
    "#         print('GRU last timestep output: ')\n",
    "#         print(gru_out[-1])\n",
    "#         print('Last hidden state: ', self.h)\n",
    "        outp = self.out(self.h[-1])\n",
    "        return F.log_softmax(outp, dim=-1)\n",
    "        \n",
    "    def init_hidden(self, batch_size):\n",
    "        return Variable(torch.zeros((1, batch_size, self.n_hidden)).cuda())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleGru(\n",
      "  (emb): Embedding(219238, 4)\n",
      "  (gru): GRU(4, 5)\n",
      "  (out): Linear(in_features=5, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = SimpleGru(vocab_size, embedding_dim, n_hidden, n_out)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_batch(X, y, lengths):\n",
    "    lengths, idx = lengths.sort(dim=0, descending=True)\n",
    "    X= X[idx]\n",
    "    y = y[idx]\n",
    "    return X.transpose(0,1), y, lengths #transport (batch x seq_length) to (seq_length*batch)\n",
    "\n",
    "# d1 = DataLoader(ds, batch_size=3)\n",
    "# it = iter(d1)\n",
    "# xs, ys, lens = next(it)\n",
    "# xs, ys, lens = sort_batch(xs,ys,lens)\n",
    "# outp = model(xs, lens.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7900, -0.6049],\n",
       "        [-0.7982, -0.5981],\n",
       "        [-0.7954, -0.6004]], grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.6049, -0.5981, -0.6004], grad_fn=<MaxBackward0>),\n",
       " tensor([1, 1, 1]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(outp, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7945, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.nll_loss(outp, Variable(ys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, train_dl, val_dl, loss_fn, opt, epochs=3):\n",
    "    num_batch = len(train_dl)\n",
    "    for epoch in tnrange(epochs):\n",
    "        y_true_train = list()\n",
    "        y_pred_train = list()\n",
    "        total_loss_train = 0\n",
    "        \n",
    "        if val_dl:\n",
    "            y_true_val = list()\n",
    "            y_pred_val = list()\n",
    "            total_loss_val = 0\n",
    "            \n",
    "        t = tqdm_notebook(iter(train_dl), leave=False, total=num_batch)\n",
    "        for X, y, lengths in t:\n",
    "            t.set_description(f'Epoch {epoch}')\n",
    "            X, y, lengths = sort_batch(X, y, lengths)\n",
    "            X = Variable(X.cuda())\n",
    "            y = Variable(y.cuda())\n",
    "            lengths = lengths.numpy()\n",
    "            \n",
    "            opt.zero_grad()\n",
    "            pred = model(X, lengths).cuda()\n",
    "            loss = loss_fn(pred, y)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            \n",
    "            t.set_postfix(loss=loss.data)\n",
    "            pred_idx = torch.max(pred, dim=1)[1]\n",
    "            \n",
    "            y_true_train += list(y.cpu().data.numpy())\n",
    "            y_pred_train += list(pred_idx.cpu().data.numpy())\n",
    "            total_loss_train += loss.data\n",
    "            \n",
    "        train_acc = accuracy_score(y_true_train, y_pred_train)\n",
    "        train_loss = total_loss_train/len(train_dl)\n",
    "        print(f'Epoch {epoch}: Train loss: {train_loss} acc: {train_acc}')\n",
    "        \n",
    "        if val_dl:\n",
    "            for X, y, lengths in tqdm_notebook(val_dl, leave=False):\n",
    "                X, y , lenghts = sort_batch(X, y, lengths)\n",
    "                X = Variable(X.cuda())\n",
    "                y = Variable(y.cuda())\n",
    "                pred = model(X, lengths.numpy())\n",
    "                loss = loss_fn(pred, y)\n",
    "                pred_idx = torch.max(pred, 1)[1]\n",
    "                y_true_val += list(y.cpu().data.numpy())\n",
    "                y_pred_val += list(pred_idx.cpu().data.numpy())\n",
    "                total_loss_val += loss.data[0]\n",
    "            valacc = accuracy_score(y_true_val, y_pred_val)\n",
    "            valloss = total_loss_val/len(val_dl)\n",
    "            print(f'Val loss: {valloss} acc: {valacc}')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(ds, batch_size=512)\n",
    "model = SimpleGru(vocab_size, embedding_dim, n_hidden, n_out).cuda()\n",
    "opt = optim.Adam(model.parameters(), 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e36506e3d5e64fc98d085303d6658f57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63fcadab2d3a4d6d9af08b8567f2dc66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2552), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Train loss: 0.12927229702472687 acc: 0.9515627177246843\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a922b790e8e44a8186d262cf36a58f5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2552), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train loss: 0.10469355434179306 acc: 0.9575453135312015\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b085d0eeb0304391b9be954edc159f53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2552), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train loss: 0.09778326004743576 acc: 0.9600427831397067\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af94c12ad3204c3b99f47e865616e6c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2552), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train loss: 0.0924949049949646 acc: 0.9621375338597773\n"
     ]
    }
   ],
   "source": [
    "fit(model=model, train_dl=train_dl, val_dl=None, loss_fn=F.nll_loss, opt=opt, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'simple_gru.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConcatPoolingGRU(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, n_hidden, n_out):\n",
    "        super().__init__()\n",
    "        self.vocab_size, self.embedding_dim, self.n_hidden, self.n_out = vocab_size, embedding_dim, n_hidden, n_out\n",
    "        self.emb=nn.Embedding(self.vocab_size, self.embedding_dim)\n",
    "        self.gru = nn.GRU(self.embedding_dim, self.n_hidden)\n",
    "        self.out = nn.Linear(self.n_hidden*3, self.n_out)\n",
    "        \n",
    "    def forward(self, seq, lengths):\n",
    "        self.h = self.init_hidden(seq.size(1), gpu)\n",
    "        embs = self.emb(seq)\n",
    "        embs = pack_padded_sequence(embs, lengths)\n",
    "        gru_out, self.h = self.gru(embs, self.h)\n",
    "        gru_out, lengths = pad_packed_sequence(gru_out)\n",
    "        avg_pool = F.adaptive_avg_pool1d(gru_out.permute(1,2,0),1).view(seq.size(1), -1)\n",
    "        print('adaptive avg pooling', avg_pool)\n",
    "        avg_pool_byhand = torch.sum(gru.out, dim=0)/Variable(torch.FloatTensor(lengths).view(-1, 1))\n",
    "        print('By Hand adaptive avg pooling', avg_pool_byhand)\n",
    "        max_pool = F.adaptive_max_pool1d(gru_out.permute(1,2,0),1).view(sequ.size(1), -1)\n",
    "        print('adative max pooling', max_pool)\n",
    "        max_pool_byhand = torch.cat([torch.max(i[:l], dim=0)[0].view(1,-1) for i, l in zip(gru_out.permute(1,0,2), lengths)], dim=0)\n",
    "        print('by hand adaptive max pooling', max_pool_byhand)\n",
    "        outp = self.out(torch.cat([self.h[-1], avg_pool_byhand, max_pool_byhand], dim=1))\n",
    "        return F.log_softmax(outp, dim=-1)\n",
    "    \n",
    "    def init_hidden(self, batch_size, gpu):\n",
    "        Variable(torch.zeros((1, batch_size, self.n_hidden)).cuda())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConcatPoolingGRU(\n",
      "  (emb): Embedding(219238, 4)\n",
      "  (gru): GRU(4, 5)\n",
      "  (out): Linear(in_features=15, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = ConcatPoolingGRU(vocab_size, embedding_dim, n_hidden, n_out)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(ds, batch_size=3)\n",
    "it = iter(dl)\n",
    "xs, ys, lens = next(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gpu' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-fb4ccf31d6d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msort_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moutp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-54-ab1007b536da>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, seq, lengths)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0membs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0membs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpack_padded_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gpu' is not defined"
     ]
    }
   ],
   "source": [
    "xs, ys,lens = sort_batch(xs, ys, lens)\n",
    "outp = model(xs, lens.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConcatPoolingGRU(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, n_hidden, n_out):\n",
    "        super().__init__()\n",
    "        self.vocab_size, self.embedding_dim, self.n_hidden, self.n_out = vocab_size, embedding_dim, n_hidden, n_out\n",
    "        self.emb=nn.Embedding(self.vocab_size, self.embedding_dim)\n",
    "        self.gru = nn.GRU(self.embedding_dim, self.n_hidden)\n",
    "        self.out = nn.Linear(self.n_hidden*3, self.n_out)\n",
    "        \n",
    "    def forward(self, seq, lengths):\n",
    "        self.h = self.init_hidden(seq.size(1))\n",
    "        embs = self.emb(seq)\n",
    "        embs = pack_padded_sequence(embs, lengths)\n",
    "        gru_out, self.h = self.gru(embs, self.h)\n",
    "        gru_out, lengths = pad_packed_sequence(gru_out)\n",
    "        avg_pool = F.adaptive_avg_pool1d(gru_out.permute(1,2,0),1).view(seq.size(1), -1)\n",
    "#         print('adaptive avg pooling', avg_pool)\n",
    "#         avg_pool_byhand = torch.FloatTensor(torch.sum(gru_out, dim=0))/Variable(torch.FloatTensor(lengths).view(-1, 1))\n",
    "#         print('By Hand adaptive avg pooling', avg_pool_byhand)\n",
    "        max_pool = F.adaptive_max_pool1d(gru_out.permute(1,2,0),1).view(seq.size(1), -1)\n",
    "#         print('adative max pooling', max_pool)\n",
    "#         max_pool_byhand = torch.cat([torch.max(i[:l], dim=0)[0].view(1,-1) for i, l in zip(gru_out.permute(1,0,2), lengths)], dim=0)\n",
    "#         print('by hand adaptive max pooling', max_pool_byhand)\n",
    "        outp = self.out(torch.cat([self.h[-1], avg_pool, max_pool], dim=1))\n",
    "        return F.log_softmax(outp, dim=-1)\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        Variable(torch.zeros((1, batch_size, self.n_hidden)).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0aab3c635c01476ebf028c82d0b9672b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3de364cd5cc4aaaae6736038aebb1fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2552), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Train loss: 0.1321483850479126 acc: 0.9498331702551522\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67ab8dfb56314d74a3c25dd570a8d70d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2552), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train loss: 0.10505302995443344 acc: 0.9573163915775096\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28ac97181ac8463dae6afe9159997355",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2552), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train loss: 0.09773273020982742 acc: 0.959960861236546\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d784dad46c548f2b53840687836d029",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2552), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train loss: 0.09225675463676453 acc: 0.9622064401334638\n"
     ]
    }
   ],
   "source": [
    "train_dl = DataLoader(ds, batch_size=512)\n",
    "model = ConcatPoolingGRU(vocab_size, embedding_dim, n_hidden, n_out).cuda()\n",
    "opt = optim.Adam(model.parameters(), 1e-2)\n",
    "fit(model=model, train_dl = train_dl, val_dl =None, loss_fn =F.nll_loss, opt=opt, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
